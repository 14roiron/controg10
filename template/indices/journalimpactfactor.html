<div id="journalimpactfactor" class="acteur">
<div class="titre">Journal Impact Factor </div>
<div class="contenu"> 
  

<h4>1/ Définition:
</h4>
<p>
Le Journal Impact Factor est un indicateur bibliométrique créé en 1955 par Eugene Garfield.
</p>

	<blockquote>
	 A journal’s impact factor is based on 2 elements: the numerator, which is the number of citations in the current year to any items published in a journal in the previous 2 years, and the denominator, which is the number of substantive articles (source items) published in the same 2 years.
    <small class="pull-right">E. Garfield,	"Journal impact factor: a brief review", Canadian Medical Association Journal, 161(8), p.979-80, 1999</small><br>
	</blockquote>
	<br/>
	
<p>
L'indice sert à évaluer une revue. Il comporte un numérateur et un dénominateur, l'idée étant de pondérer le nombre total de citations par le nombre total d'articles publiés par le chercheur.
</p>

<h4>
2/ Nombre d'articles traitant du Journal Impact Factor: 
</h4>
<h5>
a) Sur Scopus:
</h5>
<p>
Nous recherchons les articles mentionnant "impact factor" et publiés après 1959.
</p>
<p>
Nous utilisons donc l'équation de recherche: <i>TITLE-ABS-KEY ( "impact factor" )  AND  PUBYEAR  >  1959</i>  <b>(10 380 résultats).</b>
<img class="img-responsive"  src="/~groupe10/template/images/jif1.png" />

<br/>
<small class="text-center-md">Elsevier B.V. Scopus [en ligne]. 2015. Disponible sur : scopus.com (05/2015).</small>
</p>

<p>
L'étude est faite entre 1990 (avant cela, une dizaine d’article par an) et 2014. Pic présent en 2013 avec <b>1522 articles.</b>
</p>

<p>
Si l'on se concentre sur l’aspect controversé et excluant le domaine médical, on recherche les articles dont le thème comporte "impact factor" avec la mention "flaws", "critics" ou "limits" n'ayant pas trait au domaine médical. On utilise donc l’équation de recherche :
<i>( TITLE-ABS-KEY ( "impact factor" )  AND  (TITLE-ABS-KEY ( flaw* )  OR  TITLE-ABS-KEY ( critic* )  OR  TITLE-ABS-KEY ( limit* ) ))  AND  ( EXCLUDE ( SUBJAREA ,  "MEDI" ) )</i> <b>750 résulats</b>
<img class="img-responsive"  src="/~groupe10/template/images/jif2.png">
<br/>
<small class="text-center-md">Elsevier B.V. Scopus [en ligne]. 2015. Disponible sur : scopus.com (05/2015).</small>
</p>



 

<h5>
b) Sur Web of Science:
</h5>
<p > 
De 1960 à 2008 
<img class="img-responsive"  src="/~groupe10/template/images/jif3.png">
<br/>
<small class="text-center-md">Thomson Reuters. Web Of Science [en ligne]. 2015. Disponible sur : http://apps.webofknowledge.com (05/2015).</small>
</p> 
<p > 
De 2008 à 2013 
<img class="img-responsive"  src="/~groupe10/template/images/jif4.png">
<br/>
<small class="text-center-md">Thomson Reuters. Web Of Science [en ligne]. 2015. Disponible sur : http://apps.webofknowledge.com (05/2015).</small> 
 <br />
On retrouve le même pic en 2013. 
</p>
<h4>
3/ Motivation et création: 
</h4>
<p > 
D’après E.Garfield, le facteur d'impact a été crée pour ces motivations:
- Permettre une sélection des différents journaux. Rapporté tous les ans dans le Journal Citation Report. Il constate qu’il ne faut pas comparer différent domaine car le taux de citation varie selon les disciplines. 
- Cet indice n’a pas pour but d’évaluer les fluctuations à court terme. Garfield avait prévu qu’entre de mauvaises mains, il pourrait être mal employé.
- Utilisé par les bibliothèques pour savoir quel abonnement acheté et par les auteurs pour savoir ou publier. 
- En utilisant un rapport, le but est de ne pas défavorisé les petits journaux.
</p>
<h4>
4/	Réactions
</h4>
<p > 
Le choix de la durée d'"exploration" de deux ans est source de nombreuses critiques. Un autre article publié dans <i>The Scientist</i>, au contraire, indique que la durée n’aurait pas d’impact significatif. Dans tous les cas, si le facteur d’impact augmente beaucoup dans certains domaines lorsqu’on augmente la durée d’échantillonnage, le classement fourni, quant à lui, ne change pas beaucoup.
</p>
<p > 
<blockquote>
Impact Factor is not a perfect tool to measure the quality of articles but there is nothing better and it has the advantage of already being in existence and is, therefore, a good technique for scientific evaluation. Experience has shown that in each specialty the best journals are those in which it is most difficult to have an article accepted, and these are the journals that have a high impact factor. These journals existed long before the impact factor was devised. The use of impact factor as a measure of quality is widespread because it fits well with the opinion we have in each field of the best journals in our specialty.
<small class="pull-right">
C. Hoeffel, Journal impact factors [letter]. Allergy 53:1225, 1998.
</small>
</blockquote>

<p > 
En 2011, J.K. Vanclay pointe du doigt de nombreuses limites à l’utilisation du facteur d’impact :
</p>
<blockquote>
The TRIF is not a reliable indicator of journal quality, that it lacks rigour and requires normalizing before comparisons are attempted, that its 2-year timeframe is too short for meaningful trends to be established, that it lacks statistical validity, suffers database problems, and leads to problematic (if unintended) consequences.
<small class="pull-right">
J.K. Vanclay, Impact factor: outdated artefact or stepping-stone to journal certification?, <i>Scientometrics</i>, 24 Novembre 2011
</small>
</blockquote>

<p > 
Michel Zitt répond à cet article en écrivant que, pour des raisons historiques, cet indicateur est très critiqué, mais qu'il a contribué, par ses forces comme ses faiblesses, à alimenter le débat autour des indicateurs bibliométriques.
</p>
<blockquote>
The JIF: angel, devil or scapegoat? All three at a time: angel, for a unique historical role and the many avenues opened to scientometrics and other fields; devil, for a few flaws, and a brightness and market power that may have deterred users from looking aside; but also scapegoat, for misuses and abuses.
<small class="pull-right">
	M. Zitt, The journal impact factor: angel, devil, or scapegoat? A comment on J.K. Vanclay’s article 2011, <i>Scientometrics</i>, 22 Février 2012
	</small>
</blockquote>
  
</div>
